# Jailbreaking-Deep-Models
adversarial attack experiments on ImageNet classifiers using ResNet-34 &amp; DenseNet-121. Jupyter notebooks &amp; scripts cover preprocessing, baseline evaluation, single-step FGSM and multi-step PGD L∞ attacks, 32×32 patch perturbations, transferability analysis, setup, metrics, example visualizations, and reproducible experiments.
